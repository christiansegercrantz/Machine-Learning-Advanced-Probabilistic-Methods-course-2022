\documentclass{article}
\usepackage[margin=3cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{comment}
\usepackage{eurosym}

\graphicspath{ {plots/} }

\title{Advanced probabilistic methods - Sketch}
\author{Christian Segercrantz 481056}


\begin{document}
	\maketitle
	\pagebreak
\begin{align}
	\mathcal{L}(q) =& \mathbb{E}_q [\log p(\mathbf{X}, \mathbf{Z})] - \mathbb{E}_q [\log q(\mathbf{Z})] \\
	\mathbb{E}_q \log p(\mathbf{X}, \mathbf{Z}) =& \mathbb{E}_q \left[ \log p(\tau) + \log p\theta + \log p(\mathbf{z}\mid \tau) + \log p(\mathbf{x} \mid \mathbf{z} \theta)\right] \\
	=& \mathbb{E}_{q(\tau)} \left[ \log p(\tau)\right] + \mathbb{E}_{q(\theta)} \left[\log p\theta\right] + \mathbb{E}_{q(\mathbf{z})q(\tau)} \left[\log p(\mathbf{z}\mid \tau)\right] + \mathbb{E}_{q(\mathbf{z})q(\theta)} \left[\log p(\mathbf{x} \mid \mathbf{z}, \theta)\right] \\
	\mathbb{E}_q [\log q(\mathbf{Z})] =& \mathbb{E}_q \left[-\log q(\mathbf{z}) - \log q(\tau) - \log q(\theta) \right] \\
	=& - \mathbb{E}_{q(\mathbf{z})} \left[\log q(\mathbf{z})\right]  - \mathbb{E}_{q(\tau)} \left[\log q(\tau)\right]  - \mathbb{E}_{q(\theta)} \left[\log q(\theta) \right] \\
	\mathcal{L}(q) =& \mathbb{E}_{q(\tau)} \left[ \log p(\tau)\right] + \mathbb{E}_{q(\theta)} \left[\log p(\theta)\right] + \mathbb{E}_{q(\mathbf{z})q(\tau)} \left[\log p(\mathbf{z}\mid \tau)\right] + \mathbb{E}_{q(\mathbf{z})q(\theta)} \left[\log p(\mathbf{x} \mid \mathbf{z}, \theta)\right] \\
	& - \mathbb{E}_{q(\mathbf{z})} \left[\log q(\mathbf{z})\right]  - \mathbb{E}_{q(\tau)} \left[\log q(\tau)\right]  - \mathbb{E}_{q(\theta)} \left[\log q(\theta) \right]
\end{align}

\begin{align}
	p(\theta) =& \mathcal{N}(\theta \mid 0, \beta_0^{-1}) \\
	\mathbb{E}_{q(\theta)} \left[\log p(\theta)\right] =& \mathbb{E}_{q(\theta)} \left[\log \mathcal{N}(\theta \mid 0, \beta_0^{-1})\right] \\
	\propto& \mathbb{E}_{q(\theta)} \left[ -\frac{1}{2} \theta^2 \beta_0\right] \\
	=&  -\frac{1}{2} \mathbb{E}_{q(\theta)} \left[\theta^2\right] \beta_0\\
	\mathbb{E}_{q(\theta)}\left[\theta^2\right] =& \text{var}(\theta) + \mathbb{E}_{q(\theta)}\left[\theta\right]^2\\
	=& \beta_2^{-1} + m_2^2 \\
	\mathbb{E}_{q(\theta)} \left[\log p(\theta)\right] \propto & -\frac{\beta_0}{2}(\beta_2^{-1} + m_2^2) 
\end{align}

\begin{align}
	q(\theta) =& \mathcal{N}(\theta \mid m_2, \beta_2^{-1})\\
	\mathbb{E}_{q(\theta)} \left[\log q(\theta)\right] =& \mathbb{E}_{q(\theta)} \left[\log \mathcal{N}(\theta \mid m_2, \beta_2^{-1})\right] \\
	\propto & \mathbb{E}_{q(\theta)} \left[-\frac{1}{2} (\theta-m_2)^2 \beta_2\right] \\
	= & -\frac{1}{2} \mathbb{E}_{q(\theta)} \left[(\theta-m_2)^2\right] \beta_2 \\
	= & -\frac{1}{2} \mathbb{E}_{q(\theta)} \left[(\theta^2 - 2\theta m_2 +m_2^2\right] \beta_2\\
	\propto & -\frac{1}{2} \mathbb{E}_{q(\theta)} \left[\theta^2 - 2\theta m_2 \right] \beta_2\\
	= & -\frac{\beta_2}{2} (\mathbb{E}_{q(\theta)} \left[\theta^2 \right] - \mathbb{E}_{q(\theta)} \left[2\theta m_2 \right]) \\
	= & -\frac{\beta_2}{2} (\beta_2^{-1} + m_2^2 - 2m_2^2) \\
	= & -\frac{\beta_2}{2} (\beta_2^{-1} - m_2^2) \\
	= & \frac{m_2^2 \beta_2}{2} -\frac{1}{2} \\
\end{align}

\begin{align}
	p(x \mid z, \theta) =&  \prod_{n=1}^{N} \mathcal{N}(x_n \mid 0, 1) ^{z_{n1}} \mathcal{N}(x_n \mid \theta, 1) ^{z_{n2}} \\
	E_{q(z)q(\theta)}\left[\log p(x \mid z, \theta)\right] =& E_{q(z)q(\theta)}\left[\sum_{n=1}^{N} {z_{n1}}\log\mathcal{N}(x_n \mid 0, 1) +  \sum_{n=1}^{N} {z_{n2}}\log\mathcal{N}(x_n \mid \theta, 1)\right]\\
	\propto& E_{q(z)q(\theta)}\left[\sum_{n=1}^{N} {z_{n1}}\left( -\frac{1}{2}x_n^2\right)  +  \sum_{n=1}^{N} {z_{n2}}\left( -\frac{1}{2}\right)(x_n-\theta)^2 \right]\\
	=& E_{q(z)q(\theta)}\left[\sum_{n=1}^{N} {z_{n1}}\left( -\frac{1}{2}x_n^2\right)  +  \sum_{n=1}^{N} {z_{n2}}\left( -\frac{1}{2}\right)(x_n^2-2x_n\theta + \theta^2) \right] \\
	=& \sum_{n=1}^{N} E_{q(z)}\left[{z_{n1}}\right] \left( -\frac{1}{2}x_n^2\right)  +  \sum_{n=1}^{N} E_{q(z)}\left[{z_{n2}}\right] \left( -\frac{1}{2}\right)(x_n^2-2x_n E_{q(\theta)}\left[\theta\right]  + E_{q(\theta)}\left[\theta^2\right] ) \\
	E_{q(z)}\left[{z_{nk}}\right] &= r_{nk} \\
	E_{q(\theta)}\left[\theta\right]  &= m_2 \\
	E_{q(\theta)}\left[\theta^2\right]  &= \beta_2^{-1} + m_2^2\\
	E_{q(z)q(\theta)}\left[\log p(x \mid z, \theta)\right] \propto &
	\sum_{n=1}^{N} r_{n1} \left( -\frac{1}{2}x_n^2\right)  +  \sum_{n=1}^{N} r_{n2} \left( -\frac{1}{2}\right)(x_n^2-2x_n m_2  + \beta_2^{-1} + m_2^2 )\\
	=&	\sum_{n=1}^{N} r_{n1} \left( -\frac{1}{2}x_n^2\right)  +  \sum_{n=1}^{N} r_{n2} \left( -\frac{1}{2}\right)((x_n - m_2)^2  + \beta_2^{-1})
\end{align}


We denote $x_i$ as the number of black pebbles in the $i$th bag and $n$ the total amount of pebbels. 
\begin{align}
	x_i \sim& \text{Bin}(x_i \mid n,a) = {n \choose x_i}a^{x_i}(1-a)^{x_i}\\
	a \sim& \text{Beta}(a \mid 1,1) = 1 \\
	p(x\mid M_1) =&  \int_0^1 \text{Bin}(x_1 \mid n,a)\text{Bin}(x_2 \mid n,a)\text{Beta}(a \mid 1,1)\\
	=& \int_0^1 {n \choose x_1}a^{x_1}(1-a)^{n-x_1}{n \choose x_2}a^{x_2}(1-a)^{n-x_2} da\\
	=& {n \choose x_1}{n \choose x_2}\int_0^1 a^{x_1+x_2}(1-a)^{2n-x_1-x_2} da \\
	=& {n \choose x_1}{n \choose x_2}\int_0^1 a^{x_1+x_2-1+1}(1-a)^{x_1+x_2-1+1} da\\
	=& {n \choose x_1}{n \choose x_2}\text{B}(x_1+x_2+1, 2n - x_1-x_2 + 1)
\end{align}

For the second model we have 
\begin{align}
	x_i \sim& \text{Bin}(n,a_i) = {n \choose x_i}a_i^{x_i}(1-a_i)^{n-x_i} \\
	b \sim& \text{Beta}(1,1) = 1\\
\end{align}
We again note $i=b$ for black marbles and $i=w$ for the white ones.
\begin{align}
	p(x\mid M_2) =&  \int_0^1\int_0^1 \text{Bin}(x_1 \mid n,a_1)\text{Bin}(x_2 \mid n,a_2)\text{Beta}(a_1 \mid 1,1)\text{Beta}(a_2 \mid 1,1)da_1da_2\\
	=&  \int_0^1\int_0^1 {n \choose x_1}a_1^{x_1}(1-a_1)^{n-x_1}{n \choose x_2}a_2^{x_2}(1-a_2)^{n-x_2}da_1da_2\\
	=&  {n \choose x_1}{n \choose x_2}\int_0^1a_1^{x_1}(1-a_1)^{n-x_1} da_1\int_0^1 a_2^{x_2}(1-a_2)^{n-x_2}da_2\\
	=&  {n \choose x_1}{n \choose x_2}\int_0^1a_1^{x_1-1+1}(1-a_1)^{n-x_1-1+1} da_1\int_0^1 a_2^{x_2-1+1}(1-a_2)^{n-x_2-1+1}da_2\\
	=&  {n \choose x_1}{n \choose x_2}\text{B}(x_1+1,n-x_1+1) \text{B}(x_2+1,n-x_2+1)\\
\end{align}
We can now formulate the posterior odds as 
\begin{align}
	\frac{p(x\mid M_1)}{p(x\mid M_2)} =& \frac{{n \choose x_1}{n \choose x_2}\text{B}(x_1+x_2+1, 2n - x_1-x_2 + 1)}{{n \choose x_1}{n \choose x_2}\text{B}(x_1+1,n-x_1+1) \text{B}(x_2+1,n-x_2+1)}\\
	=& \frac{\text{B}(x_1+x_2+1, 2n - x_1-x_2 + 1)}{\text{B}(x_1+1,n-x_1+1) \text{B}(x_2+1,n-x_2+1)}
\end{align}
\end{document}




