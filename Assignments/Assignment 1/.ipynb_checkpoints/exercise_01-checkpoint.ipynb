{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53d33039fc4dd1e7ccae8cf8e8407df3",
     "grade": false,
     "grade_id": "cell-81a11fcca9d13123",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## CS-E4820 Machine Learning: Advanced Probabilistic Methods (spring 2022)\n",
    "\n",
    "Pekka Marttinen, Prayag Tiwari, Vishnu Raj, Tianyu Cui, Yogesh Kumar, Antti Pöllänen, Louis Filstroff, Alex Aushev, Zheyang Shen, Nikitin Alexander , Sebastiaan De Peuter.\n",
    "\n",
    "\n",
    "## Exercise 1, due on Tuesday 25th January at 23:50.\n",
    "\n",
    "#### Contents\n",
    "1. Problem 1: Coins\n",
    "2. Problem 2: False positive paradox\n",
    "3. Problem 3: Markov blanket definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a11a5ad2434f18e1e33edbad83f6a811",
     "grade": false,
     "grade_id": "cell-bc24dcb36e66ad40",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Problem 1: Coins\n",
    "\n",
    "There are two bent coins ($c_1$ and $c_2$) with different properties, and your objective is to guess which coin was used (i.e. the value of random variable $C \\in \\{c_1, c_2\\}$), after learning whether the result of the coin toss (i.e. the random variable $X \\in \\{\\mbox{h}, \\mbox{t}\\}$) was heads or tails.\n",
    "\n",
    "As prior knowledge, we know the probability of each coin resulting in tails: $p(X=\\mbox{t} \\mid C=c_1) = \\theta_1$ and $p(X=\\mbox{t} \\mid C=c_2) = \\theta_2$.\n",
    "In addition, the prior probability for using coin $c_1$ is known: $p(C=c_1) = \\pi_1$.\n",
    "\n",
    "Give the posterior probability of coin $c_1$ being used for the toss, $p(C=c_1 \\mid X)$, in terms of $\\theta_1$, $\\theta_2$ and $\\pi_1$, for both $X=\\mbox{t}$ and $X=\\mbox{h}$.\n",
    "\n",
    "Furthermore, plot the posterior probability of coin $c_1$, $p(C=c_1 \\mid X=\\mbox{t})$, as a function of $\\theta_1$, when we have $\\theta_2 = 0.5$ and $\\pi_1 = 0.5$.\n",
    "\n",
    "\n",
    "Write your solutions in LateX or attach a picture in the answer cell provided below. You can add a picture using the command ```!(imagename_in_the_folder.jpg)```. Latex in here works similarly as you would write it normally! You can use some of the definitions from the exercise description as a reference. The list of valid Latex commands in Jypyter notebook can be found here: http://www.onemathematicalcat.org/MathJaxDocumentation/TeXSyntax.htm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd0322302def95c65dcf81c531f9a29d",
     "grade": false,
     "grade_id": "cell-e90f90331ea43f79",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# define some variables:\n",
    "theta_2 = 0.5\n",
    "pi_1 = 0.5\n",
    "\n",
    "# compute posterior probability of c_1\n",
    "theta_1 = range(0, 1, 0.05)\n",
    "post_c1 = \n",
    "\n",
    "\n",
    "# plot the result\n",
    "plt.plot(theta_1, post_c1)\n",
    "plt.title('$p(C = c_1 \\\\mid X = t)$ as a function of $\\\\theta_1$')\n",
    "plt.xlabel('$\\\\theta_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19e422a9939e89609047e8f5e1edadd7",
     "grade": false,
     "grade_id": "cell-4500ce1134bbdbfa",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Problem 2: False positive paradox\n",
    "\n",
    "Consider a hypothetical lie detector that is ''fairly reliable'', in the sense that it will correctly detect 98\\% of all lies, and also classify as true 98\\% of all statements that are actually true.\n",
    "This lie detector is being used in an attempt to detect academic dishonesty, by asking ''did you cheat?'' from all students participating in an exam of a machine learning course.\n",
    "(This example is still hypothetical.)\n",
    "\n",
    "For the purposes of this question, assume as prior knowledge that there are 300 students taking the exam, and a single student has chosen to cheat.\n",
    "We will further assume that all students deny having cheated. \n",
    "If the detector now flags a particular student X as a cheater, how likely is it that X has, in fact, cheated in the exam?\n",
    "\n",
    "Write your solutions in LateX or attach a picture in the answer cell provided below. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c08166977aa1369bc657868d8a618cce",
     "grade": false,
     "grade_id": "cell-3b24eb8a6cead773",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Problem 3: Markov blanket definition\n",
    "Consider the Bayesian network in below. What is the Markov blanket of each variable? (see Barber: [Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online), ch. 2.1, Definition 2.5)\n",
    "\n",
    "![](markov.png)\n",
    "Define Markov blanket for each variable $A,B,C,D,E,F$. You answer should list the nodes that form the Markov blanket for each node. For example, for node A, your answer should look like so $A = \\{B, D, E\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "$B = \\{ \\}$ #EXERCISE\n",
    "\n",
    "$C = \\{ \\}$ #EXERCISE\n",
    "\n",
    "$D = \\{ \\}$ #EXERCISE\n",
    "\n",
    "$E = \\{ \\}$ #EXERCISE\n",
    "\n",
    "$F = \\{ \\}$ #EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
